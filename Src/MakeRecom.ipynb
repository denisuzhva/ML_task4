{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metadata\n",
    "\n",
    "NODES = 196591\n",
    "EDGES = 950327\n",
    "FULL_EDGES = 2097245\n",
    "CHECKINS = 6442892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Check-ins and permute them\n",
    "\n",
    "ci_dataset = np.load('../Dataset/ci_ids.npy') # [usr, place]\n",
    "p = np.random.permutation(CHECKINS)\n",
    "ci_dataset = ci_dataset[p, :].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy with no clusterization (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 107092\n"
     ]
    }
   ],
   "source": [
    "## Count users\n",
    "\n",
    "u_usr = np.unique(ci_dataset[:, 0]).astype(np.int32)\n",
    "n_usr = u_usr.size\n",
    "print('Unique users: %i' % n_usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train users: 96383\n",
      "Number of test users: 10709\n",
      "Number of train check-ins: 5765488\n",
      "Number of test check-ins: 677404\n"
     ]
    }
   ],
   "source": [
    "## Divide into train and test data\n",
    "\n",
    "test_size = n_usr // 10 # test dataset is 5 times smaller than the full dataset\n",
    "print('Number of train users: %i' % (n_usr - test_size))\n",
    "print('Number of test users: %i' % test_size)\n",
    "\n",
    "# permute users\n",
    "p = np.random.permutation(n_usr)\n",
    "u_usr_rand = u_usr[p]\n",
    "\n",
    "# divide users\n",
    "test_usrs = u_usr_rand[:test_size]\n",
    "train_usrs = u_usr_rand[test_size:]\n",
    "\n",
    "# mark arguments of test and train checkins in ci_dataset\n",
    "test_checkins_args = np.argwhere(np.in1d(ci_dataset[:, 0], test_usrs)).flatten()\n",
    "train_checkins_args = np.argwhere(np.in1d(ci_dataset[:, 0], train_usrs)).flatten()\n",
    "assert test_checkins_args.size + train_checkins_args.size == CHECKINS\n",
    "print('Number of train check-ins: %i' % train_checkins_args.size)\n",
    "print('Number of test check-ins: %i' % test_checkins_args.size)\n",
    "\n",
    "# get checkins from ci_dataset\n",
    "test_checkins = ci_dataset[test_checkins_args, 1].flatten()\n",
    "train_checkins = ci_dataset[train_checkins_args, 1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count checkins\n",
    "\n",
    "uniq_train, cnt_train = np.unique(train_checkins, return_counts=True)\n",
    "uniq_test, cnt_test = np.unique(test_checkins, return_counts=True)\n",
    "\n",
    "# concatenate unique elements and their counts\n",
    "train_data = np.concatenate((uniq_train.reshape(-1, 1),\n",
    "                             cnt_train.reshape(-1, 1)),\n",
    "                             axis=1).astype(np.int32)\n",
    "test_data = np.concatenate((uniq_test.reshape(-1, 1),\n",
    "                            cnt_test.reshape(-1, 1)),\n",
    "                            axis=1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Ratings\n",
      "    Place ID  Count\n",
      "1      55033   5147\n",
      "2      19542   5131\n",
      "3       9410   4243\n",
      "4      10259   3623\n",
      "5      58725   3192\n",
      "6      23256   3110\n",
      "7      14470   3085\n",
      "8      10190   3039\n",
      "9       9246   3032\n",
      "10      9241   2917\n"
     ]
    }
   ],
   "source": [
    "## Sort with respect to counts and then flip to make ratings\n",
    "\n",
    "train_data_srt = train_data[train_data[:, 1].argsort()]\n",
    "train_data_srt = np.flip(train_data_srt, axis=0)\n",
    "\n",
    "# visualization\n",
    "train_dataframe = pd.DataFrame(data=train_data_srt[:10],\n",
    "                               index=np.arange(1, 11),\n",
    "                               columns=['Place ID', 'Count'])\n",
    "print('Train Ratings')\n",
    "print(train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.039\n"
     ]
    }
   ],
   "source": [
    "## Calculate the accuracy metric: hits / (k * test_size) where k = 10\n",
    "\n",
    "# get top 10 locations from train data\n",
    "train_top10_loc = train_data_srt[:10, 0]\n",
    "\n",
    "# find counts in the test dataset that correspond to those locations\n",
    "coinc = np.argwhere(np.in1d(test_data[:, 0].flatten(), train_top10_loc)).flatten()\n",
    "sum_test_counts = np.sum(test_data[coinc][:, 1])\n",
    "acc = sum_test_counts / (10 * test_size)\n",
    "print('Baseline accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy with clusterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load array of exemplars\n",
    "\n",
    "exemp = np.load('./exemplars.npy')\n",
    "exemp_unique = np.unique(exemp) # unique exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a dictionary of clusters\n",
    "\n",
    "clust_dict = dict()\n",
    "for exemplar in exemp_unique:\n",
    "    clust_dict[exemplar] = np.argwhere(exemp == exemplar).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make top 10 for each cluster (among the users in the train selection)\n",
    "\n",
    "clust_top10 = dict()\n",
    "for exemplar in exemp_unique:\n",
    "    \n",
    "    # mark users in a cluster that are in the train selection\n",
    "    train_clust_args = np.argwhere(np.in1d(train_usrs, clust_dict[exemplar]))\n",
    "    \n",
    "    # get their corresponding checkins\n",
    "    train_clust_checkins = ci_dataset[train_clust_args, 1].flatten()\n",
    "    \n",
    "    # count checkins\n",
    "    uniq_clust_train, cnt_clust_train = np.unique(train_clust_checkins, return_counts=True)\n",
    "    \n",
    "    # make a mini-dataset [location, count]\n",
    "    train_clust_data = np.concatenate((uniq_clust_train.reshape(-1, 1),\n",
    "                                       cnt_clust_train.reshape(-1, 1)),\n",
    "                                       axis=1).astype(np.int32)\n",
    "    \n",
    "    # sort & flip\n",
    "    train_clust_data_srt = train_clust_data[train_clust_data[:, 1].argsort()]\n",
    "    train_clust_data_srt = np.flip(train_clust_data_srt, axis=0)\n",
    "    \n",
    "    # store the top 10 locations\n",
    "    clust_top10[exemplar] = train_clust_data_srt[:10, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5593696  162742  152811  155420  155497  159042  159211  160040  162659\n",
      "  163480]\n"
     ]
    }
   ],
   "source": [
    "print(clust_top10[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  27600]\n",
      " [2347203]\n",
      " [6174887]]\n"
     ]
    }
   ],
   "source": [
    "print(np.argwhere(ci_dataset[:, 1] == 5593696))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusterized accuracy: 0.000075\n"
     ]
    }
   ],
   "source": [
    "## Calculate the accuracy metric for the clusters\n",
    "\n",
    "total_sum = 0\n",
    "for exemplar in exemp_unique:\n",
    "    \n",
    "    # mark users in a cluster that are in the test selection\n",
    "    test_clust_args = np.argwhere(np.in1d(test_usrs, clust_dict[exemplar]))\n",
    "    \n",
    "    # get their corresponding checkins\n",
    "    test_clust_checkins = ci_dataset[test_clust_args, 1].flatten()\n",
    "    \n",
    "    # count checkins\n",
    "    uniq_clust_test, cnt_clust_test = np.unique(test_clust_checkins, return_counts=True)\n",
    "    \n",
    "    # make a mini-dataset [location, count]\n",
    "    test_clust_data = np.concatenate((uniq_clust_test.reshape(-1, 1),\n",
    "                                      cnt_clust_test.reshape(-1, 1)),\n",
    "                                      axis=1).astype(np.int32)\n",
    "    \n",
    "    # get coincidences with the top 10 locations for the cluster (arguments of locations)\n",
    "    clust_coinc = np.argwhere(np.in1d(test_clust_data[:, 0].flatten(), clust_top10[exemplar])).flatten()\n",
    "    \n",
    "    # count the coincidences \n",
    "    clust_sum_test_counts = np.sum(test_clust_data[clust_coinc][:, 1])\n",
    "    total_sum += clust_sum_test_counts\n",
    "    \n",
    "acc_clust = total_sum / (10 * test_size)\n",
    "print('Clusterized accuracy: %f' % acc_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
